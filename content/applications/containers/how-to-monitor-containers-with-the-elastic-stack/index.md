---
slug: Mastering Container Monitoring with the Elastic Stack
description: 'Discover how to harness the power of Filebeat and Metricbeat to effortlessly monitor Docker container logs and metrics. Unlock the potential of the Elastic Stack in Kibana for seamless visualization'
keywords: ["elastic", "filebeat", "metricbeat", "elasticsearch", "kibana", "docker", "container", "nginx"]
tags: ["container","docker","nginx"]
modified: 2024-05-03
modified_by:
  name: Utho
published: 2024-05-03
title: Container Instrumentation with the Elastic Stack
authors: ["Pawan Kumar"]
---

Container Instrumentation with the Elastic Stack

The [Elastic Stack](https://www.elastic.co/products) can monitor a variety of data generated by [Docker](https://www.docker.com/) containers. In this guide, you will set up a Utho to analyze and visualize container logs and metrics using tools like Kibana, Beats, and Elasticsearch. Once finished, you will be able to configure your system to collect data for additional containers automatically.

## Before you Begin

If you haven't already, create a Utho account and set up a Compute Instance. Refer to our guides on Getting Started with Utho and Creating a Compute Instance for assistance.

Ensure your system is up-to-date and secure by following our [Setting Up and Securing a Compute Instance](/docs/products/compute/compute-instances/guides/set-up-and-secure/) guide. Consider tasks like setting the timezone, configuring your hostname, creating a limited user account, and enhancing SSH access.

Secure your system with a firewall. If you're on Ubuntu or Debian-based systems, check out our [UFW Guide](/docs/guides/configure-firewall-with-ufw/). For rpm or CentOS-based systems, refer to our [FirewallD Guide](/docs/guides/introduction-to-firewalld-on-centos/). After firewall setup, ensure the necessary ports are open for SSH connections to proceed with the rest of the guide.

        sudo ufw allow ssh

Begin by installing Docker on your Utho using the instructions provided in [the installation guide from the Docker project](https://docs.docker.com/).

ote: The services outlined in this guide are bound to localhost, meaning they are not accessible from remote hosts outside of the Utho. This setup ensures the Elasticsearch REST API remains private to localhost and is not remotely accessible from the internet. If you decide to further configure Elasticsearch and related components beyond this guide, ensure your firewall is properly configured to block traffic to the Elasticsearch and Kibana nodes from the internet (specifically ports 9200 and 9300 for Elasticsearch, and port 5601 for Kibana) to maintain proper security.

## Install Elastic Stack Components

Before setting up monitoring for running containers, you'll need to install the necessary components for collecting and shipping logs and metrics to Elasticsearch.

### Debian-Based Distributions

Follow these steps to configure the Elastic `apt` repository and install the required packages along with their dependencies:

Install the official Elastic APT package signing key:

        wget -qO - https://artifacts.elastic.co/GPG-KEY-elasticsearch | sudo apt-key add -

Install the `apt-transport-https` package, necessary for retrieving `deb` packages served over HTTPS:

        sudo apt-get install apt-transport-https

Add the APT repository information to your server's list of sources:

        echo "deb https://artifacts.elastic.co/packages/6.x/apt stable main" | sudo tee -a /etc/apt/sources.list.d/elastic-6.x.list

Update the list of available packages:

        sudo apt-get update

Before proceeding with Elasticsearch installation, ensure the presence of the Java runtime. On systems like Ubuntu 18.04 LTS, you can install a compatible Java runtime using the `default-jre-headless` package:

        sudo apt-get install default-jre-headless

Install Elasticsearch, Kibana, Filebeat, and Metricbeat:

        sudo apt-get install elasticsearch kibana filebeat metricbeat

### Redhat-Based Distributions

To configure the `rpm` repository for `yum` and related packaging tools, follow these steps:

Trust the Elastic signing key:

        sudo rpm --import https://artifacts.elastic.co/GPG-KEY-elasticsearch

Create a yum repository configuration to utilize the Elastic yum repository:

        {{< file "/etc/yum.repos.d/elasticsearch.repo" ini >}}
        [elasticsearch-6.x]
        name=Elastic repository for 6.x packages
        baseurl=https://artifacts.elastic.co/packages/6.x/yum
        gpgcheck=1
        gpgkey=https://artifacts.elastic.co/GPG-KEY-elasticsearch
        enabled=1
        autorefresh=1
        type=rpm-md
        {{< /file >}}

Refresh the `yum` cache to ensure any newly available packages are included:

        sudo yum update

Prior to Elasticsearch installation, ensure the Java runtime environment is available. On CentOS systems, you can install a compatible Java runtime using a headless OpenJDK package:

        sudo yum install java-11-openjdk-headless

Proceed with installing Elasticsearch, Kibana, Filebeat, and Metricbeat:

        sudo yum install elasticsearch kibana filebeat metricbeat

## Configure The Elastic Stack

To effectively capture container metrics, each component of the Elastic Stack requires proper configuration.

### Elasticsearch

In the file `/etc/elasticsearch/jvm.options`, uncomment two values starting with `-Xm`. These settings specify JVM memory allocation. It's recommended to allocate 50% of the available system RAM for these settings. For instance, on a system with 1GB of RAM, these settings should be:

    {{< file "/etc/elasticsearch/jvm.options" yml >}}
    -Xms512m
    -Xmx512m
     {{< /file >}}

Before launching Elasticsearch, ensure to install essential plugins for processing geoip and user-agent data.

        sudo /usr/share/elasticsearch/bin/elasticsearch-plugin install ingest-user-agent
        sudo /usr/share/elasticsearch/bin/elasticsearch-plugin install ingest-geoip

Once these settings are configured, initiate the `elasticsearch` service.

        sudo systemctl start elasticsearch

After a brief wait for Elasticsearch to initialize, verify its responsiveness over the REST API:You should observe output resembling the following:

        curl http://localhost:9200

You should see output similar to the following:

        {
          "name" : "iQEk_-M",
          "cluster_name" : "elasticsearch",
          "cluster_uuid" : "tQeLgbKrTNOp2AoqdmTItw",
          "version" : {
                "number" : "6.5.4",
                "build_flavor" : "default",
                "build_type" : "deb",
                "build_hash" : "d2ef93d",
                "build_date" : "2018-12-17T21:17:40.758843Z",
                "build_snapshot" : false,
                "lucene_version" : "7.5.0",
                "minimum_wire_compatibility_version" : "5.6.0",
                "minimum_index_compatibility_version" : "5.0.0"
          },
          "tagline" : "You Know, for Search"
        }

    Elasticsearch is ready to index documents.

### Kibana

Most of Kibana's default configurations are suitable for this guide's objectives, requiring no adjustments. Simply start the `kibana` service.

    sudo systemctl start kibana

### Filebeat

Utilize the `docker` input to enable Filebeat to dynamically capture logs from running containers. This eliminates the need to specify Docker log file paths and enables Filebeat to automatically detect containers as they start.

Add the following lines near the top of the Filebeat configuration file under the `filebeat.inputs` configuration key to instruct the `filebeat` daemon to capture Docker container logs:

    {{< file "/etc/filebeat/filebeat.yml" yml >}}
     filebeat.inputs:
    - type: docker
    containers.ids:
    - '*'
    processors:
    - add_docker_metadata: ~
    {{< /file >}}

Uncomment the following line and set its value to `true` to enable Filebeat to generate associated Kibana dashboards for collected container logs:

        {{< file "/etc/filebeat/filebeat.yml" yml >}}
        setup.dashboards.enabled: true
        {{< /file >}}

Add the following `autodiscover` configuration to the end of the `filebeat.yml` file:

        {{< file "/etc/filebeat/filebeat.yml" yml >}}
        filebeat.autodiscover:
        providers:
        - type: docker
        hints.enabled: true
        {{< /file >}}

Enable the `nginx` module, which will be utilized later in this tutorial:

        sudo /usr/bin/filebeat modules enable nginx

The rest of the configuration file will direct Filebeat to send logs to the locally-running Elasticsearch instance, which can remain unchanged. Proceed to start Filebeat:

        sudo systemctl start filebeat

### Metricbeat

Similar to Filebeat, configure Metricbeat to dynamically discover running containers for monitoring purposes:

Metricbeat employs modules to collect container metrics. Use the following command to enable the `docker` and `nginx` modules:

        sudo /usr/bin/metricbeat modules enable docker
        sudo /usr/bin/metricbeat modules enable nginx

Uncomment the following line and set its value to `true` to enable Metricbeat to generate associated Kibana dashboards for collected container logs:

         {{< file "/etc/metricbeat/metricbeat.yml" yml >}}
         setup.dashboards.enabled: true
         {{< /file >}}

The rest of the configuration file will instruct Metricbeat to send logs to the locally-running Elasticsearch instance, which can remain as is. Initiate Metricbeat:

          sudo systemctl start metricbeat

## Visualizing Container Logs and Metrics
Below is an illustration showcasing how Filebeat and Metricbeat seamlessly capture container data, accessible within Kibana.

To initiate, launch a basic nginx Docker container on your Utho.

        sudo docker run --name nginx -P -d --label co.elastic.logs/module=nginx nginx

- Execute the following command to run the web server in the background, exposing the listening HTTP service under a random port number.

- The `--label` argument serves as a [hint](https://www.elastic.co/guide/en/beats/filebeat/current/configuration-autodiscover-hints.html) for Filebeat, aiding in the automatic parsing of log formats for specific container types, such as nginx:

Establish a secure connection to Kibana by creating an SSH tunnel to port 5601 on your Utho.

        ssh -L 5601:localhost:5601 <user@ip-address>

- Replace `<user@ip-address>` with your Utho's username and IP address.

- This command forwards port 5601 from your local machine to port 5601 on your Utho.

- For detailed instructions on setting up SSH tunnels across different platforms, refer to our [Create an SSH Tunnel for MySQL guide](/docs/guides/create-an-ssh-tunnel-for-mysql-remote-access/).

Access Kibana by navigating to `http://localhost:5601` in your web browser. This will lead you to the initial landing page for Kibana.

Click on the **Management** link located in the lower-left sidebar. This will direct you to the Management page. From there, click on **Index Patterns** to access the Index Pattern configuration page.

Index Patterns define how Elasticsearch indices are interpreted by Kibana. To ensure proper visualization, it's crucial to set up a default index pattern first. Select `filebeat-*` from the left side of the page to configure the filebeat-* index pattern.

Click the **star icon** in the upper-right corner to designate this index pattern as the default in Kibana. This completes the configuration of the default index pattern in Kibana.

    Kibana is now properly configured with a default index pattern.

Filebeat and Metricbeat are configured to automatically set up Elasticsearch and Kibana, loading dashboards and index patterns for immediate use. Navigate to **Dashboard** in the left-hand sidebar to access the Dashboard page.

In the Search bar, enter "container" to display pre-configured dashboards for system containers. Click on the **[Metricbeat Docker] Overview** link.

The **[Metricbeat Docker] Overview** dashboard will load, providing insights into various aspects of currently running container metrics. It includes details about running containers, the total count of running, paused, and stopped containers, as well as metrics on container resource utilization.

Scrolling further down, it also shows graphs indicating container resource usage over time, including CPU, memory, and network activity.

1.  Before moving on to other Kibana visualizations, generate some log activity from nginx by sending HTTP requests to the listening container. First, find which port the container is listening for requests on using the `docker` command:

        docker ps

You can expect to observe output resembling the following:

        CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                   NAMES
        3f0c6d284f1f        nginx               "nginx -g 'daemon ofâ€¦"   23 minutes ago      Up 23 minutes       0.0.0.0:32769->80/tcp   nginx

Based on this information, we can confirm that the HTTP server is accessible by sending requests to port 32769, which is redirected to port 80 within the container. Keep in mind that the port number on your system might vary.

Issue multiple requests to this port using the `curl` command, replacing `<port>` with the number obtained in the previous step:

        for i in $(seq 1 10) ; do curl localhost:<port> ; done

With a significant number of logs now available in Kibana for this container, navigate to **Discover** in the left-hand sidebar of Kibana. This will display the following screen:

- The histogram at the top of the page illustrates the total count of container logs over time.
- Below the graph, a table lists the contents of individual log entries.
- Clicking on the arrows beside each log's timestamp reveals detailed information for each captured log.

Repeat the previous `for ...` command to send another set of ten `curl` requests to the container. Observe how the log histogram dynamically updates to reflect the new logs.

Navigate to **Dashboard** in the left-hand sidebar, then click it again to access the dashboard selection screen. Utilize the search bar to look for "nginx".

Click on the **[Filebeat Nginx] Access and error logs** link. This will open a dashboard featuring various visualizations related to nginx activity.

## Additional Modules

This tutorial has illustrated how Filebeat and Metricbeat can automatically capture container metrics and logs without requiring explicit configuration of log file paths or settings. In addition to the nginx examples demonstrated here, you can explore additional modules that can be loaded into Filebeat and Metricbeat for monitoring other services. Links to these modules are provided below for further exploration.
